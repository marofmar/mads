{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"/home/snu/Desktop/hw1-DeepLearning/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/snu/Desktop/hw1-DeepLearning/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"/home/snu/Desktop/hw1-DeepLearning/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/home/snu/Desktop/hw1-DeepLearning/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>34.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.237429</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.380526</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-0.359771</td>\n",
       "      <td>-0.494084</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.133862</td>\n",
       "      <td>0.438810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.530900</td>\n",
       "      <td>-0.044265</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>0.509136</td>\n",
       "      <td>0.288858</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>17.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "3  17.0  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
       "4  24.0  1.237429  0.061043  0.380526  0.761564 -0.359771 -0.494084  0.006494   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "1 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "2  0.115982 -0.221083  ...   -0.036876  0.074412 -0.071407  0.104744   \n",
       "3  0.521502 -1.191311  ...    0.143997  0.402492 -0.048508 -1.371866   \n",
       "4 -0.133862  0.438810  ...   -0.245682 -0.530900 -0.044265  0.079168   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "1 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "2  0.548265  0.104094  0.021491  0.021293   27.50      0  \n",
       "3  0.390814  0.199964  0.016371 -0.014605   34.09      0  \n",
       "4  0.509136  0.288858 -0.022705  0.011836   17.28      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's merge valid into train, CV is more convenient for me!\n",
    "train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Class\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "5         0\n",
      "6         0\n",
      "7         0\n",
      "8         0\n",
      "9         0\n",
      "10        0\n",
      "11        0\n",
      "12        0\n",
      "13        0\n",
      "14        0\n",
      "15        0\n",
      "16        0\n",
      "17        0\n",
      "18        0\n",
      "19        0\n",
      "20        0\n",
      "21        0\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        0\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        0\n",
      "...     ...\n",
      "9970      0\n",
      "9971      0\n",
      "9972      0\n",
      "9973      0\n",
      "9974      0\n",
      "9975      0\n",
      "9976      0\n",
      "9977      0\n",
      "9978      0\n",
      "9979      0\n",
      "9980      0\n",
      "9981      0\n",
      "9982      0\n",
      "9983      0\n",
      "9984      0\n",
      "9985      0\n",
      "9986      0\n",
      "9987      0\n",
      "9988      0\n",
      "9989      0\n",
      "9990      0\n",
      "9991      0\n",
      "9992      0\n",
      "9993      0\n",
      "9994      0\n",
      "9995      0\n",
      "9996      0\n",
      "9997      0\n",
      "9998      0\n",
      "9999      0\n",
      "\n",
      "[39200 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#train[class] split by 0(normal) 1(fraud) to see how skew the data is\n",
    "#count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "dist_class = pd.DataFrame(train['Class'])\n",
    "print(dist_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38808\n",
       "1      392\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class.value_counts() # SUPER Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFYCAYAAABZHSXVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XFQnPWdx/HPLst2xe5KFtmcucvZS09D7gQSSuWyTBpJ\nwlmZnpdWiEASZ67UqRfMmIo1iJYkk1JIlB5NpaexzcklanLSmw71HMjVQ8aUlTvcG0q8xsTO3E2G\nRNhVkARCWGHvjxt35DQJWh428Hu//go/fvvk+/iHb57n2Sy2aDQaFQAAmPfs8R4AAADMDqIPAIAh\niD4AAIYg+gAAGILoAwBgCKIPAIAhHPEewGqh0Ll4jwAAwKxKTXV/4jpX+gAAGMLS6I+NjWndunX6\n53/+Z509e1abN29WaWmpHnjgAY2Pj0uSWlpadNddd6moqEgvvviiJCkSiaiiokIlJSXatGmTTp8+\nLUk6ceKEiouLVVxcrB07dlg5OgAA846l0f/7v/97XXfddZKkffv2qbS0VM8//7xuvPFGNTc3a3R0\nVI2NjXr22Wd18OBBNTU1aWhoSC+99JI8Ho9eeOEF3Xfffaqvr5ck1dTUqKqqSocPH9b58+fV0dFh\n5fgAAMwrlkX/d7/7nd5++23ddtttkqSuri6tXbtWkpSXl6dAIKCenh6lp6fL7XbL5XIpKytLwWBQ\ngUBA+fn5kiS/369gMKjx8XH19fUpIyNjyjEAAMD0WPZGvj179uh73/uefvGLX0iSLly4IKfTKUlK\nSUlRKBRSOByW1+uNvcbr9X5s3W63y2azKRwOy+PxxPZ+eIwrWbAgSQ5HwkyeGgAAc5Il0f/FL36h\n5cuXa/HixZ/4/Uv9jp9Psz7d3xM0ODg6rX0AAMwXl3r3viXRf/XVV3X69Gm9+uqreuedd+R0OpWU\nlKSxsTG5XC719/fL5/PJ5/MpHA7HXjcwMKDly5fL5/MpFAopLS1NkUhE0WhUqampGhoaiu398BgA\nAGB6LHmm39DQoJ///Of6p3/6JxUVFWnLli3y+/1qa2uTJB09elSrVq1SZmament7NTw8rJGREQWD\nQWVnZys3N1etra2SpPb2duXk5CgxMVFLlixRd3f3lGMAAIDpmbUP59m6dau2b9+uI0eOaNGiRVq/\nfr0SExNVUVGhsrIy2Ww2lZeXy+12q6CgQJ2dnSopKZHT6VRdXZ0kqaqqStXV1ZqcnFRmZqb8fv9s\njQ8AwJxni0734fgcxSfyAQBMwyfyAQBgOKIPAIAhiD4AAIaY979lz0qFezbGewTg99a8/bl4jwBg\nlnClDwCAIYg+AACGIPoAABiC6AMAYAiiDwCAIYg+AACGIPoAABiC6AMAYAiiDwCAIYg+AACGIPoA\nABiC6AMAYAiiDwCAIYg+AACGIPoAABiC6AMAYAiiDwCAIYg+AACGIPoAABiC6AMAYAiiDwCAIYg+\nAACGIPoAABjCYdWBL1y4oMrKSr377ru6ePGitmzZora2Nr355ptKTk6WJJWVlem2225TS0uLmpqa\nZLfbtWHDBhUVFSkSiaiyslJnzpxRQkKCamtrtXjxYp04cUI7d+6UJC1dulS7du2y6hQAAJhXLIt+\ne3u7brnlFt17773q6+vTN7/5Ta1YsUIPPvig8vLyYvtGR0fV2Nio5uZmJSYmqrCwUPn5+Wpvb5fH\n41F9fb2OHTum+vp6NTQ0qKamRlVVVcrIyFBFRYU6Ojq0evVqq04DAIB5w7Lb+wUFBbr33nslSWfP\nntXChQs/cV9PT4/S09PldrvlcrmUlZWlYDCoQCCg/Px8SZLf71cwGNT4+Lj6+vqUkZEhScrLy1Mg\nELDqFAAAmFcsf6ZfXFyshx56SFVVVZKkQ4cO6Z577tF3vvMdvffeewqHw/J6vbH9Xq9XoVBoyrrd\nbpfNZlM4HJbH44ntTUlJUSgUsvoUAACYFyy7vf+hw4cP67e//a2++93vqqqqSsnJyVq2bJn279+v\nJ598UitWrJiyPxqNfuJxPmn9Uns/asGCJDkcCZ9teMAAqanueI8AYJZYFv3jx48rJSVFN9xwg5Yt\nW6aJiQndfPPNSklJkSStWbNGO3fu1O23365wOBx73cDAgJYvXy6fz6dQKKS0tDRFIhFFo1GlpqZq\naGgotre/v18+n++ycwwOjlpzgsA8EQqdi/cIAGbYpX6Yt+z2fnd3tw4cOCBJCofDGh0dVXV1tU6f\nPi1J6urq0k033aTMzEz19vZqeHhYIyMjCgaDys7OVm5urlpbWyX935sCc3JylJiYqCVLlqi7u1uS\ndPToUa1atcqqUwAAYF6x7Eq/uLhYjz76qEpLSzU2Nqbq6molJSVp27Ztuuaaa5SUlKTa2lq5XC5V\nVFSorKxMNptN5eXlcrvdKigoUGdnp0pKSuR0OlVXVydJqqqqUnV1tSYnJ5WZmSm/32/VKQAAMK/Y\notN5MD6HWXnrsnDPRsuODcyW5u3PxXsEADNs1m/vAwCAqwvRBwDAEEQfAABDEH0AAAxB9AEAMATR\nBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB\n9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABD\nEH0AAAzhsOrAFy5cUGVlpd59911dvHhRW7ZsUVpamh5++GFNTEwoNTVVjz/+uJxOp1paWtTU1CS7\n3a4NGzaoqKhIkUhElZWVOnPmjBISElRbW6vFixfrxIkT2rlzpyRp6dKl2rVrl1WnAADAvGLZlX57\ne7tuueUWHTp0SA0NDaqrq9O+fftUWlqq559/XjfeeKOam5s1OjqqxsZGPfvsszp48KCampo0NDSk\nl156SR6PRy+88ILuu+8+1dfXS5JqampUVVWlw4cP6/z58+ro6LDqFAAAmFcsi35BQYHuvfdeSdLZ\ns2e1cOFCdXV1ae3atZKkvLw8BQIB9fT0KD09XW63Wy6XS1lZWQoGgwoEAsrPz5ck+f1+BYNBjY+P\nq6+vTxkZGVOOAQAArsyy2/sfKi4u1jvvvKOnnnpKf/M3fyOn0ylJSklJUSgUUjgcltfrje33er0f\nW7fb7bLZbAqHw/J4PLG9Hx4DAABcmeXRP3z4sH7729/qu9/9rqLRaGz9o3/+qE+zfqm9H7VgQZIc\njoRpTguYJzXVHe8RAMwSy6J//PhxpaSk6IYbbtCyZcs0MTGha6+9VmNjY3K5XOrv75fP55PP51M4\nHI69bmBgQMuXL5fP51MoFFJaWpoikYii0ahSU1M1NDQU2/vhMS5ncHDUqlME5oVQ6Fy8RwAwwy71\nw7xlz/S7u7t14MABSVI4HNbo6Kj8fr/a2tokSUePHtWqVauUmZmp3t5eDQ8Pa2RkRMFgUNnZ2crN\nzVVra6uk/3tTYE5OjhITE7VkyRJ1d3dPOQYAALgyW3Q698g/g7GxMT366KM6e/asxsbGdP/99+uW\nW27R9u3bdfHiRS1atEi1tbVKTExUa2urfvazn8lms2nTpk268847NTExoccee0z//d//LafTqbq6\nOt1www16++23VV1drcnJSWVmZuqRRx657BxWXsUU7tlo2bGB2dK8/bl4jwBghl3qSt+y6F8tiD5w\neUQfmH9m/fY+AAC4uhB9AAAMQfQBADAE0QcAwBBEHwAAQxB9AAAMQfQBADAE0QcAwBBEHwAAQxB9\nAAAMQfQBADAE0QcAwBBEHwAAQxB9AAAMQfQBADAE0QcAwBBEHwAAQxB9AAAMQfQBADAE0QcAwBBE\nHwAAQxB9AAAMQfQBADAE0QcAwBBEHwAAQxB9AAAMQfQBADAE0QcAwBAOKw++d+9evfHGG/rggw/0\n7W9/W//2b/+mN998U8nJyZKksrIy3XbbbWppaVFTU5Psdrs2bNigoqIiRSIRVVZW6syZM0pISFBt\nba0WL16sEydOaOfOnZKkpUuXateuXVaeAgAA84Zl0X/99dd16tQpHTlyRIODg/r617+uv/iLv9CD\nDz6ovLy82L7R0VE1NjaqublZiYmJKiwsVH5+vtrb2+XxeFRfX69jx46pvr5eDQ0NqqmpUVVVlTIy\nMlRRUaGOjg6tXr3aqtMAAGDesOz2/pe//GX96Ec/kiR5PB5duHBBExMTH9vX09Oj9PR0ud1uuVwu\nZWVlKRgMKhAIKD8/X5Lk9/sVDAY1Pj6uvr4+ZWRkSJLy8vIUCASsOgUAAOYVy670ExISlJSUJElq\nbm7WV77yFSUkJOjQoUP6h3/4B6WkpOh73/uewuGwvF5v7HVer1ehUGjKut1ul81mUzgclsfjie1N\nSUlRKBS67BwLFiTJ4Uiw4AyB+SE11R3vEQDMEkuf6UvSr371KzU3N+vAgQM6fvy4kpOTtWzZMu3f\nv19PPvmkVqxYMWV/NBr9xON80vql9n7U4ODoZxscMEQodC7eIwCYYZf6Yd7Sd++/9tpreuqpp/TM\nM8/I7XZr5cqVWrZsmSRpzZo1OnnypHw+n8LhcOw1AwMD8vl88vl8sav4SCSiaDSq1NRUDQ0Nxfb2\n9/fL5/NZeQoAAMwblkX/3Llz2rt3r55++unYu/W3bt2q06dPS5K6urp00003KTMzU729vRoeHtbI\nyIiCwaCys7OVm5ur1tZWSVJ7e7tycnKUmJioJUuWqLu7W5J09OhRrVq1yqpTAABgXrHs9v7LL7+s\nwcFBbdu2Lbb2jW98Q9u2bdM111yjpKQk1dbWyuVyqaKiQmVlZbLZbCovL5fb7VZBQYE6OztVUlIi\np9Opuro6SVJVVZWqq6s1OTmpzMxM+f1+q04BAIB5xRadzoPxOczK55WFezZadmxgtjRvfy7eIwCY\nYXF5pg8AAK4eRB8AAEMQfQAADEH0AQAwBNEHAMAQRB8AAEMQfQAADEH0AQAwBNEHAMAQRB8AAEMQ\nfQAADEH0AQAwBNEHAMAQRB8AAEMQfQAADEH0AQAwBNEHAMAQ04p+ZWXlx9bKyspmfBgAAGAdx+W+\n2dLSosOHD+vUqVPauHFjbD0SiSgcDls+HAAAmDmXjf6dd96pnJwcPfTQQ9q6dWts3W6360//9E8t\nHw4AAMycy0ZfkhYuXKiDBw/q3LlzGhoaiq2fO3dOycnJlg4HAABmzhWjL0nf//739fOf/1xer1fR\naFSSZLPZ9Morr1g6HAAAmDnTin5XV5def/11fe5zn7N6HgAAYJFpvXv/xhtvJPgAAMxx07rS/4M/\n+ANt3LhRX/rSl5SQkBBbf+CBBywbDAAAzKxpRT85OVkrV660ehYAAGChaUV/y5YtVs8BAAAsNq3o\n/9mf/ZlsNlvsa5vNJrfbra6ursu+bu/evXrjjTf0wQcf6Nvf/rbS09P18MMPa2JiQqmpqXr88cfl\ndDrV0tKipqYm2e12bdiwQUVFRYpEIqqsrNSZM2eUkJCg2tpaLV68WCdOnNDOnTslSUuXLtWuXbs+\n+9kDAGCQaUX/xIkTsT+Pj48rEAjorbfeuuxrXn/9dZ06dUpHjhzR4OCgvv71r2vlypUqLS3VHXfc\noR/+8Idqbm7W+vXr1djYqObmZiUmJqqwsFD5+flqb2+Xx+NRfX29jh07pvr6ejU0NKimpkZVVVXK\nyMhQRUWFOjo6tHr16t/vvwIAAAb41L9wx+l0avXq1fr1r3992X1f/vKX9aMf/UiS5PF4dOHCBXV1\ndWnt2rWSpLy8PAUCAfX09Cg9PV1ut1sul0tZWVkKBoMKBALKz8+XJPn9fgWDQY2Pj6uvr08ZGRlT\njgEAAK5sWlf6zc3NU75+55131N/ff9nXJCQkKCkpKfb6r3zlKzp27JicTqckKSUlRaFQSOFwWF6v\nN/Y6r9f7sXW73S6bzaZwOCyPxxPb++ExAADAlU0r+m+88caUrz//+c+roaFhWn/Br371KzU3N+vA\ngQP6y7/8y9j6h5/s9/99mvVL7f2oBQuS5HAkXHEfYKrUVHe8RwAwS6YV/draWknS0NCQbDabrrvu\numkd/LXXXtNTTz2ln/70p3K73UpKStLY2JhcLpf6+/vl8/nk8/mm/Ma+gYEBLV++XD6fT6FQSGlp\naYpEIopGo0pNTZ3y+f8fHuNyBgdHpzUrYKpQ6Fy8RwAwwy71w/y0nukHg0GtW7dOd9xxh26//XZ9\n9atfVW9v72Vfc+7cOe3du1dPP/107Bfz+P1+tbW1SZKOHj2qVatWKTMzU729vRoeHtbIyIiCwaCy\ns7OVm5ur1tZWSVJ7e7tycnKUmJioJUuWqLu7e8oxAADAlU3rSr++vl4/+clPdPPNN0uS/uu//ks1\nNTV67rnnLvmal19+WYODg9q2bVtsra6uTo899piOHDmiRYsWaf369UpMTFRFRYXKyspks9lUXl4u\nt9utgoICdXZ2qqSkRE6nU3V1dZKkqqoqVVdXa3JyUpmZmfL7/b/P+QMAYAxbdBoPxjdv3qyDBw9O\nWbvnnnv0j//4j5YNNlOsvHVZuGejZccGZkvz9kv/8A5gbvq9bu/b7Xa1tbXp/PnzOn/+vF5++eUp\nn8EPAACuftO6vb9r1y7t3r1bjz32mOx2u9LS0vT973/f6tkAAMAMmtaV/q9//Ws5nU79x3/8h7q6\nujQ5OamOjg6rZwMAADNoWtFvaWnRk08+Gfv6wIED+uUvf2nZUAAAYOZNK/oTExNTnuHb7Z/603sB\nAECcTeuZ/po1a1RcXKwvfelLmpyc1Ouvvz7l0/UAAMDVb1rR37Jli2699Vb95je/kc1m044dO7R8\n+XKrZwMAADNoWtGXpOzsbGVnZ1s5CwAAsBAP5wEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDA\nEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEA\nMATRBwDAEEQfAABDEH0AAAxhafRPnjypdevW6dChQ5KkyspK/dVf/ZU2b96szZs369VXX5UktbS0\n6K677lJRUZFefPFFSVIkElFFRYVKSkq0adMmnT59WpJ04sQJFRcXq7i4WDt27LByfAAA5hWHVQce\nHR3V7t27tXLlyinrDz74oPLy8qbsa2xsVHNzsxITE1VYWKj8/Hy1t7fL4/Govr5ex44dU319vRoa\nGlRTU6OqqiplZGSooqJCHR0dWr16tVWnAQDAvGHZlb7T6dQzzzwjn8932X09PT1KT0+X2+2Wy+VS\nVlaWgsGgAoGA8vPzJUl+v1/BYFDj4+Pq6+tTRkaGJCkvL0+BQMCqUwAAYF6xLPoOh0Mul+tj64cO\nHdI999yj73znO3rvvfcUDofl9Xpj3/d6vQqFQlPW7Xa7bDabwuGwPB5PbG9KSopCoZBVpwAAwLxi\n2e39T/LXf/3XSk5O1rJly7R//349+eSTWrFixZQ90Wj0E1/7SeuX2vtRCxYkyeFI+GwDAwZITXXH\newQAs2RWo//R5/tr1qzRzp07dfvttyscDsfWBwYGtHz5cvl8PoVCIaWlpSkSiSgajSo1NVVDQ0Ox\nvf39/Vd8fDA4ODrzJwLMI6HQuXiPAGCGXeqH+Vn9J3tbt26NvQu/q6tLN910kzIzM9Xb26vh4WGN\njIwoGAwqOztbubm5am1tlSS1t7crJydHiYmJWrJkibq7uyVJR48e1apVq2bzFAAAmLMsu9I/fvy4\n9uzZo76+PjkcDrW1tWnTpk3atm2brrnmGiUlJam2tlYul0sVFRUqKyuTzWZTeXm53G63CgoK1NnZ\nqZKSEjmdTtXV1UmSqqqqVF1drcnJSWVmZsrv91t1CgAAzCu26HQejM9hVt66LNyz0bJjA7Oleftz\n8R4BwAy7Km7vAwCA+CH6AAAYgugDAGAIog8AgCGIPgAAhiD6AAAYgugDAGAIog8AgCGIPgAAhiD6\nAAAYgugDAGAIog8AgCGIPgAAhiD6AAAYgugDAGAIog8AgCGIPgAAhiD6AAAYgugDAGAIog8AgCGI\nPgAAhiD6AAAYgugDAGAIog8AgCGIPgAAhiD6AAAYgugDAGAIog8AgCEsjf7Jkye1bt06HTp0SJJ0\n9uxZbd68WaWlpXrggQc0Pj4uSWppadFdd92loqIivfjii5KkSCSiiooKlZSUaNOmTTp9+rQk6cSJ\nEyouLlZxcbF27Nhh5fgAAMwrlkV/dHRUu3fv1sqVK2Nr+/btU2lpqZ5//nndeOONam5u1ujoqBob\nG/Xss8/q4MGDampq0tDQkF566SV5PB698MILuu+++1RfXy9JqqmpUVVVlQ4fPqzz58+ro6PDqlMA\nAGBesSz6TqdTzzzzjHw+X2ytq6tLa9eulSTl5eUpEAiop6dH6enpcrvdcrlcysrKUjAYVCAQUH5+\nviTJ7/crGAxqfHxcfX19ysjImHIMAABwZQ7LDuxwyOGYevgLFy7I6XRKklJSUhQKhRQOh+X1emN7\nvF7vx9btdrtsNpvC4bA8Hk9s74fHuJwFC5LkcCTM1GkB805qqjveIwCYJZZF/0qi0ejvvX6pvR81\nODj66QYDDBMKnYv3CABm2KV+mJ/Vd+8nJSVpbGxMktTf3y+fzyefz6dwOBzbMzAwEFv/8Co+Eoko\nGo0qNTVVQ0NDsb0fHgMAAFzZrEbf7/erra1NknT06FGtWrVKmZmZ6u3t1fDwsEZGRhQMBpWdna3c\n3Fy1trZKktrb25WTk6PExEQtWbJE3d3dU44BAACuzLLb+8ePH9eePXvU19cnh8OhtrY2PfHEE6qs\nrNSRI0e0aNEirV+/XomJiaqoqFBZWZlsNpvKy8vldrtVUFCgzs5OlZSUyOl0qq6uTpJUVVWl6upq\nTU5OKjMzU36/36pTAABgXrFFp/NgfA6z8nll4Z6Nlh0bmC3N25+L9wgAZthV8UwfAADED9EHAMAQ\nRB8AAEMQfQAADEH0AQAwBNEHAMAQRB8AAEMQfQAADEH0AQAwBNEHAMAQRB8AAEMQfQAADEH0AQAw\nBNEHAMAQRB8AAEMQfQAADEH0AQAwBNEHAMAQRB8AAEMQfQAADEH0AQAwBNEHAMAQRB8AAEMQfQAA\nDEH0AQAwBNEHAMAQRB8AAEM4ZvMv6+rq0gMPPKCbbrpJknTzzTfrW9/6lh5++GFNTEwoNTVVjz/+\nuJxOp1paWtTU1CS73a4NGzaoqKhIkUhElZWVOnPmjBISElRbW6vFixfP5ikAADBnzWr0JenWW2/V\nvn37Yl8/8sgjKi0t1R133KEf/vCHam5u1vr169XY2Kjm5mYlJiaqsLBQ+fn5am9vl8fjUX19vY4d\nO6b6+no1NDTM9ikAADAnxf32fldXl9auXStJysvLUyAQUE9Pj9LT0+V2u+VyuZSVlaVgMKhAIKD8\n/HxJkt/vVzAYjOfoAADMKbN+pf/222/rvvvu0/vvv6/7779fFy5ckNPplCSlpKQoFAopHA7L6/XG\nXuP1ej+2brfbZbPZND4+Hns9AAC4tFmN/he+8AXdf//9uuOOO3T69Gndc889mpiYiH0/Go1+4us+\n7fpHLViQJIcj4bMNDBggNdUd7xEAzJJZjf7ChQtVUFAgSfrjP/5jXX/99ert7dXY2JhcLpf6+/vl\n8/nk8/kUDodjrxsYGNDy5cvl8/kUCoWUlpamSCSiaDR6xav8wcFRS88JmOtCoXPxHgHADLvUD/Oz\n+ky/paVFP/vZzyRJoVBI7777rr7xjW+ora1NknT06FGtWrVKmZmZ6u3t1fDwsEZGRhQMBpWdna3c\n3Fy1trZKktrb25WTkzOb4wMAMKfN6pX+mjVr9NBDD+mVV15RJBLRzp07tWzZMm3fvl1HjhzRokWL\ntH79eiUmJqqiokJlZWWy2WwqLy+X2+1WQUGBOjs7VVJSIqfTqbq6utkcHwCAOc0Wnc6D8TnMyluX\nhXs2WnZsYLY0b38u3iMAmGFXxe19AAAQP0QfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB\n9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABD\nEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABDEH0AAAxB9AEAMIQj3gN8\nFj/4wQ/U09Mjm82mqqoqZWRkxHskAACuenMu+v/+7/+u//mf/9GRI0f0u9/9TlVVVTpy5Ei8xwIw\ni3a8WhPvEYDf267bHp31v3PO3d4PBAJat26dJOmLX/yi3n//fZ0/fz7OUwEAcPWbc9EPh8NasGBB\n7Guv16tQKBTHiQAAmBvm3O39/y8ajV72+6mpbsv+7o4nWiw7NoBL+0lRXbxHAOakOXel7/P5FA6H\nY18PDAwoNTU1jhMBADA3zLno5+bmqq2tTZL05ptvyufz6fOf/3ycpwIA4Oo3527vZ2Vl6c///M9V\nXFwsm82mHTt2xHskAADmBFv0Sg/FAQDAvDDnbu8DAIDPhugDAGAIoo+r0g9+8APdfffdKi4u1m9+\n85t4jwMY5eTJk1q3bp0OHToU71Eww+bcG/kw//FRy0D8jI6Oavfu3Vq5cmW8R4EFuNLHVYePWgbi\nx+l06plnnpHP54v3KLAA0cdVh49aBuLH4XDI5XLFewxYhOjjqse/KgWAmUH0cdXho5YBwBpEH1cd\nPmoZAKzBJ/LhqvTEE0+ou7s79lHLaWlp8R4JMMLx48e1Z88e9fX1yeFwaOHChfrxj3+s5OTkeI+G\nGUD0AQAwBLf3AQAwBNEHAMAQRB8AAEMQfQAADEH0AQAwBL9wB8C0DAwMaO/evTp58qSuvfZaSdLW\nrVv1zjvvqLOzU0888UScJwRwJUQfwBVFo1GVl5dr/fr1sbi/9dZb+uY3v6lt27bFeToA00X0AVxR\nIBCQzWbTxo0bY2tLly7Vyy+/rFdeeSW29q//+q/66U9/KqfTqYmJCe3du1d/9Ed/pKamJrW0tOia\na66Ry+XS448/rvHxcT300EOSpLGxMd19990qLCyc9XMDTEL0AVzRqVOnlJ6e/rH16667bsrXw8PD\n+ru/+zs+xAORAAAB3klEQVQtWrRITz/9tJ577jlt375d+/btU1tbm66//nq99tprGhgYUCAQ0JIl\nS7Rr1y5dvHhRL7744mydDmAsog/gihISEjQxMXHFfddff722b9+uaDSqUCikFStWSJIKCwv1rW99\nS7fffru++tWv6k/+5E/kcDj0/PPPq7KyUqtXr9bdd99t9WkAxuPd+wCu6Oabb9Z//ud/fmz9rbfe\n0oULFyRJkUhE27Zt0+7du3Xo0CFt3rw5tu+RRx5RY2OjrrvuOpWXl6ujo0Nf/OIX9S//8i+68847\nFQgEpuwHYA2iD+CKbr31Vl177bXav39/bO3UqVP627/9WyUkJEiSRkZGZLfb9Yd/+Ie6ePGiXnnl\nFY2Pj+v999/Xj3/8Y91www0qLS3Vxo0b1dvbq1/+8pfq7e2V3+/Xjh07dPbsWX3wwQfxOkXACNze\nBzAt+/fvV21trb72ta8pOTlZn/vc59TQ0KC3335bkpScnKyvfe1rKiws1KJFi1RWVqaHH35YnZ2d\nGhkZUWFhoTwejxwOh2pqavTee+9px44dcjqdikajuvfee+Vw8L8kwEr8lj0AAAzB7X0AAAxB9AEA\nMATRBwDAEEQfAABDEH0AAAxB9AEAMATRBwDAEEQfAABD/C+fpRqAfKsfPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47caa97f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Class\", palette=\"Greens_d\",data=train);\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "1 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "2  0.115982 -0.221083  ...   -0.036876  0.074412 -0.071407  0.104744   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "1 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "2  0.548265  0.104094  0.021491  0.021293   27.50      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount = pd.DataFrame(train['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "normAmount = scaler.fit_transform(amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['normAmount'] = normAmount\n",
    "#train['normAmount']=scaler.fit_transform(train['Amount'])\n",
    "#train['normAmount'] = scaler.fit_transform(train['Amount'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjustData(dataF):\n",
    "    Col = pd.DataFrame(dataF['Amount'])\n",
    "    scaler = StandardScaler()\n",
    "    normAmount = scaler.fit_transform(Col)\n",
    "    dataF['normAmount'] = normAmount\n",
    "    dataF = dataF.drop(['Time','Amount'], axis = 1)\n",
    "    return dataF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.072264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.260541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "\n",
       "         V8        V9     ...           V22       V23       V24       V25  \\\n",
       "0  0.377436 -1.387024     ...      0.005274 -0.190321 -1.175575  0.647376   \n",
       "1 -0.270533  0.817739     ...      0.798278 -0.137458  0.141267 -0.206010   \n",
       "2  0.115982 -0.221083     ...      0.074412 -0.071407  0.104744  0.548265   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  normAmount  \n",
       "0 -0.221929  0.062723  0.061458  123.50      0    0.164843  \n",
       "1  0.502292  0.219422  0.215153   69.99      0   -0.072264  \n",
       "2  0.104094  0.021491  0.021293   27.50      0   -0.260541  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train['normAmount'] = scaler.fit_transform(train['Amount'].reshape(-1, 1))\n",
    "train = train.drop(['Time','Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.072264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.260541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237429</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.380526</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-0.359771</td>\n",
       "      <td>-0.494084</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.133862</td>\n",
       "      <td>0.438810</td>\n",
       "      <td>-0.207358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.530900</td>\n",
       "      <td>-0.044265</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>0.509136</td>\n",
       "      <td>0.288858</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.305827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "3  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
       "4  1.237429  0.061043  0.380526  0.761564 -0.359771 -0.494084  0.006494   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "1 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "2  0.115982 -0.221083  0.460230     ...     -0.036876  0.074412 -0.071407   \n",
       "3  0.521502 -1.191311  0.724396     ...      0.143997  0.402492 -0.048508   \n",
       "4 -0.133862  0.438810 -0.207358     ...     -0.245682 -0.530900 -0.044265   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.164843  \n",
       "1  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.072264  \n",
       "2  0.104744  0.548265  0.104094  0.021491  0.021293      0   -0.260541  \n",
       "3 -1.371866  0.390814  0.199964  0.016371 -0.014605      0   -0.231340  \n",
       "4  0.079168  0.509136  0.288858 -0.022705  0.011836      0   -0.305827  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['Class'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.164843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.072264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153197</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>-0.260541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269321</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>-0.231340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237429</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.380526</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-0.359771</td>\n",
       "      <td>-0.494084</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.133862</td>\n",
       "      <td>0.438810</td>\n",
       "      <td>-0.207358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066351</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.530900</td>\n",
       "      <td>-0.044265</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>0.509136</td>\n",
       "      <td>0.288858</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>-0.305827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "3  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
       "4  1.237429  0.061043  0.380526  0.761564 -0.359771 -0.494084  0.006494   \n",
       "\n",
       "         V8        V9       V10     ...           V20       V21       V22  \\\n",
       "0  0.377436 -1.387024 -0.054952     ...     -0.208038 -0.108300  0.005274   \n",
       "1 -0.270533  0.817739  0.753074     ...      0.408542 -0.009431  0.798278   \n",
       "2  0.115982 -0.221083  0.460230     ...     -0.153197 -0.036876  0.074412   \n",
       "3  0.521502 -1.191311  0.724396     ...     -0.269321  0.143997  0.402492   \n",
       "4 -0.133862  0.438810 -0.207358     ...     -0.066351 -0.245682 -0.530900   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  normAmount  \n",
       "0 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458    0.164843  \n",
       "1 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   -0.072264  \n",
       "2 -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293   -0.260541  \n",
       "3 -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605   -0.231340  \n",
       "4 -0.044265  0.079168  0.509136  0.288858 -0.022705  0.011836   -0.305827  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      0\n",
       "       ..\n",
       "9970    0\n",
       "9971    0\n",
       "9972    0\n",
       "9973    0\n",
       "9974    0\n",
       "9975    0\n",
       "9976    0\n",
       "9977    0\n",
       "9978    0\n",
       "9979    0\n",
       "9980    0\n",
       "9981    0\n",
       "9982    0\n",
       "9983    0\n",
       "9984    0\n",
       "9985    0\n",
       "9986    0\n",
       "9987    0\n",
       "9988    0\n",
       "9989    0\n",
       "9990    0\n",
       "9991    0\n",
       "9992    0\n",
       "9993    0\n",
       "9994    0\n",
       "9995    0\n",
       "9996    0\n",
       "9997    0\n",
       "9998    0\n",
       "9999    0\n",
       "Name: Class, Length: 39200, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resampling\n",
    "# Oversampling techniques for classification problems\n",
    "# SMOTE, ADASYN\n",
    "# Reference: The Right Way to Oversample in Predictive Modeling (https://beckernick.github.io/oversampling-modeling/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['normAmount'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_class.isnull().sum()\n",
    "# class나 amount에 null 값이 없음을 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSMOTE creates synthetic observations of the minority class (bad loans) by:\\n\\n1.Finding the k-nearest-neighbors for minority class observations (finding similar observations)\\n2.Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observation.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SMOTE creates synthetic observations of the minority class (bad loans) by:\n",
    "\n",
    "1.Finding the k-nearest-neighbors for minority class observations (finding similar observations)\n",
    "2.Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced-learn 0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetClass = np.array(pd.DataFrame(train['Class'])).ravel()\n",
    "featureData = train.drop('Class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.164843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.072264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153197</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>-0.260541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269321</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>-0.231340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237429</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.380526</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-0.359771</td>\n",
       "      <td>-0.494084</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.133862</td>\n",
       "      <td>0.438810</td>\n",
       "      <td>-0.207358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066351</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.530900</td>\n",
       "      <td>-0.044265</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>0.509136</td>\n",
       "      <td>0.288858</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>-0.305827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "3  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
       "4  1.237429  0.061043  0.380526  0.761564 -0.359771 -0.494084  0.006494   \n",
       "\n",
       "         V8        V9       V10     ...           V20       V21       V22  \\\n",
       "0  0.377436 -1.387024 -0.054952     ...     -0.208038 -0.108300  0.005274   \n",
       "1 -0.270533  0.817739  0.753074     ...      0.408542 -0.009431  0.798278   \n",
       "2  0.115982 -0.221083  0.460230     ...     -0.153197 -0.036876  0.074412   \n",
       "3  0.521502 -1.191311  0.724396     ...     -0.269321  0.143997  0.402492   \n",
       "4 -0.133862  0.438810 -0.207358     ...     -0.066351 -0.245682 -0.530900   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  normAmount  \n",
       "0 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458    0.164843  \n",
       "1 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   -0.072264  \n",
       "2 -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293   -0.260541  \n",
       "3 -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605   -0.231340  \n",
       "4 -0.044265  0.079168  0.509136  0.288858 -0.022705  0.011836   -0.305827  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.1.1 Naive over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(featureData, targetClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 38808), (1, 38808)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77616"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.164843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.072264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153197</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>-0.260541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269321</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>-0.231340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237429</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.380526</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-0.359771</td>\n",
       "      <td>-0.494084</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.133862</td>\n",
       "      <td>0.438810</td>\n",
       "      <td>-0.207358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066351</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.530900</td>\n",
       "      <td>-0.044265</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>0.509136</td>\n",
       "      <td>0.288858</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>-0.305827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "1 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "2  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544 -0.096717   \n",
       "3  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
       "4  1.237429  0.061043  0.380526  0.761564 -0.359771 -0.494084  0.006494   \n",
       "\n",
       "         7         8         9     ...           19        20        21  \\\n",
       "0  0.377436 -1.387024 -0.054952    ...    -0.208038 -0.108300  0.005274   \n",
       "1 -0.270533  0.817739  0.753074    ...     0.408542 -0.009431  0.798278   \n",
       "2  0.115982 -0.221083  0.460230    ...    -0.153197 -0.036876  0.074412   \n",
       "3  0.521502 -1.191311  0.724396    ...    -0.269321  0.143997  0.402492   \n",
       "4 -0.133862  0.438810 -0.207358    ...    -0.066351 -0.245682 -0.530900   \n",
       "\n",
       "         22        23        24        25        26        27        28  \n",
       "0 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.164843  \n",
       "1 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.072264  \n",
       "2 -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293 -0.260541  \n",
       "3 -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605 -0.231340  \n",
       "4 -0.044265  0.079168  0.509136  0.288858 -0.022705  0.011836 -0.305827  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkX = pd.DataFrame(X_resampled)\n",
    "checkX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77616"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 테스트와 밸리데이션 셋도 같은 방식으로 데이터 전 처리를 해 줘야겠지? - 함수로 만들어야겟다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe training set is used to fit the models; \\nthe validation set is used to estimate prediction error for model selection; \\nthe test set is used for assessment of the generalization error of the final chosen model. \\nIdeally, the test set should be kept in a “vault,” \\nand be brought out only at the end of the data analysis.\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The training set is used to fit the models; \n",
    "the validation set is used to estimate prediction error for model selection; \n",
    "the test set is used for assessment of the generalization error of the final chosen model. \n",
    "Ideally, the test set should be kept in a “vault,” \n",
    "and be brought out only at the end of the data analysis.\n",
    "'''\n",
    "#Elements of statistical learning page 222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build a model!\n",
    "> 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Var 1 부터 28 까지 중에서 몇 개 골라내는건, 약간 의미가 없을 듯 싶다. 그냥 마치 완전 연관 없는 값들이\n",
    "# 우연히 같이 움직이고 하는데, 그런거나 감지하게 될 것 같아. 그래서 다 끌고 가보겠다. 아마 28개 feature도 줄일 대로 줄여놓은 것일 거라고 생각한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수는 var 1부터 28 그리고 Normalized Amount 까지 해서 총 29개이다. 그런데 데이터는 4만 개도 되지 않는다. \n",
    "# 심히 오버피팅이 우려된다.\n",
    "# C의 range를 다변화 하여 최선의 값을 찾아보아야 겠다. - Cross Validation을 통한 K fold 점수로 최선의 값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report, f1_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make use of the validation set\n",
    "#### > L1 or L2\n",
    "#### > C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(X, y):\n",
    "    C_list = [0.01, 0.1, 1, 10, 100]\n",
    "    L_list = ['l1','l2']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    \n",
    "    # d= {\"L1\": values, 'L2': [1,2,3]} by row\n",
    "    \n",
    "    combine = []\n",
    "    for c_param in C_list:\n",
    "        \n",
    "        print(\"=============================================\")\n",
    "        print(\"Parameter C: \", c_param)\n",
    "        print(\"=============================================\")\n",
    "        diff_penalty = [] # first L1, second L2\n",
    "        for L_num in L_list:\n",
    "            estimator = LogisticRegression(C = c_param, penalty = L_num)\n",
    "            estimator.fit(X_train, y_train)\n",
    "            y_pred = estimator.predict(X_test)\n",
    "            score = f1_score(y_test,y_pred)\n",
    "            diff_penalty.append(score)\n",
    "            #score = cross_val_score(estimator = estimator,X, y, scoring = f1_score(y_test, y_pred))\n",
    "            print(\"Penalty value: \", L_num)\n",
    "            print(\"F1 score with \",L_num,\"is\", score)\n",
    "            # print(diff_penalty)\n",
    "        combine.append(diff_penalty)\n",
    "    idx = np.array(C_list)\n",
    "    result_table = pd.DataFrame(data = combine, index = idx, columns = [\"l1\", \"l2\"])\n",
    "    result_table.index.name = 'Parameter C'\n",
    "    result_table.set_index([C_list])\n",
    "    print(result_table)\n",
    "    best = result_table.max().max()\n",
    "    print(\"The highest score is: \",best)\n",
    "    the_C = np.argmax(np.max(result_table, axis=1))\n",
    "    the_P = np.argmax(np.max(result_table, axis=0))\n",
    "    print(\"The best Parameter C for the score is :\", the_C)\n",
    "    print(\"The best Penalty value for the score is: \", the_P)\n",
    "    \n",
    "    return the_C, the_P\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Parameter C:  0.01\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.941000587324\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.941063523388\n",
      "=============================================\n",
      "Parameter C:  0.1\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.942580164057\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.943891932138\n",
      "=============================================\n",
      "Parameter C:  1\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.943841735801\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.943641003828\n",
      "=============================================\n",
      "Parameter C:  10\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.943590834175\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.943641003828\n",
      "=============================================\n",
      "Parameter C:  100\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.943590834175\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.943641003828\n",
      "                   l1        l2\n",
      "Parameter C                    \n",
      "0.01         0.941001  0.941064\n",
      "0.10         0.942580  0.943892\n",
      "1.00         0.943842  0.943641\n",
      "10.00        0.943591  0.943641\n",
      "100.00       0.943591  0.943641\n",
      "The highest score is:  0.943891932138\n",
      "The best Parameter C for the score is : 0.1\n",
      "The best Penalty value for the score is:  l2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10000000000000001, 'l2')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(['Index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: test, True Y = result\n",
    "def predict(File, y_true):\n",
    "    File = adjustData(File)\n",
    "    the = cv_score(X_resampled, y_resampled)\n",
    "    lr = LogisticRegression(C = the[0], penalty = the[1]) # C 값 변경 가능, L1, L2 가능\n",
    "    lr.fit(X_resampled, y_resampled)\n",
    "    y_pred = lr.predict(File)\n",
    "    F1_score = f1_score(y_true = y_true.as_matrix(), y_pred = y_pred)\n",
    "    print(\"The F1_score of the test is: \", F1_score)\n",
    "    return y_pred, F1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Parameter C:  0.01\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.942718241387\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.944962342656\n",
      "=============================================\n",
      "Parameter C:  0.1\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.944713563606\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.945613296865\n",
      "=============================================\n",
      "Parameter C:  1\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.945712782746\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.945513831913\n",
      "=============================================\n",
      "Parameter C:  10\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.945712782746\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.945364673713\n",
      "=============================================\n",
      "Parameter C:  100\n",
      "=============================================\n",
      "Penalty value:  l1\n",
      "F1 score with  l1 is 0.945712782746\n",
      "Penalty value:  l2\n",
      "F1 score with  l2 is 0.945364673713\n",
      "                   l1        l2\n",
      "Parameter C                    \n",
      "0.01         0.942718  0.944962\n",
      "0.10         0.944714  0.945613\n",
      "1.00         0.945713  0.945514\n",
      "10.00        0.945713  0.945365\n",
      "100.00       0.945713  0.945365\n",
      "The highest score is:  0.945712782746\n",
      "The best Parameter C for the score is : 1.0\n",
      "The best Penalty value for the score is:  l1\n",
      "The F1_score of the test is:  0.0612640558356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0]), 0.061264055835595195)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result.as_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(trueY, predY):\n",
    "    trueY = \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = adjustData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_resampled = lr.predict(X_test_undersample.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 스코어를 매길 때에도 고려할 점이 있다.\n",
    "# 1) Fraud를 normal로 보는 실수, 2) Normal을 Fraud 로 보는 실수\n",
    "# 위의 두 가지 중에 어느 것을 더 피하고 싶은지 살펴보면, 내 개인적 기준으로는 1) 이다.\n",
    "# 과제에서는 score를 매기는 방식을 지정해 줬는데, 나만의 score 만들어 보아도 재밌겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
