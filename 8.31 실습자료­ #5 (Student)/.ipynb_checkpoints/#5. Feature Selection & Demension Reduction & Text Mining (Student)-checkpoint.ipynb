{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction & Text Mining\n",
    "FIRA 빅데이터 플랫폼 과정 <데이터마이닝> - 2017.08.31.목 14:00-18:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Feature Selection & Dimension Reduction\n",
    "- 1-1. Review\n",
    "- 1-2. RFE : Recursive Feature Elimination `sklearn.feature_selection.RFE`\n",
    "- 1-3. PCA : `sklearn.decompostion.pca`\n",
    "- 1-4. 실습 : 변수 선택을 활용한 신용 등급 분류 모델 만들기\n",
    "\n",
    "### 2. Text Mining\n",
    "- 2-1. Data : The Internet Movie Script Database (IMSDb)\n",
    "- 2-2. Preprocessing : tokenizing, stemming, removing stopwords\n",
    "- 2-3. Word Cloud\n",
    "- 2-4. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dimension Reduction\n",
    "---\n",
    "\n",
    "#### 1-1. Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수별 설명 : CodeList\n",
    "pd.read_csv('CodeList-classification.csv').iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df\n",
    "df = pd.read_csv('german_classification.csv').set_index('OBS#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing : Dummy Variables & Scaling & Change Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dummy varaibles : preprocessed_df\n",
    "get_dummies_cols = ['CHK_ACCT', 'HISTORY', 'SAV_ACCT', 'EMPLOYMENT', 'JOB']\n",
    "dummied_df = pd.get_dummies(df, columns=get_dummies_cols)\n",
    "\n",
    "# scaling\n",
    "scaling_cols = ['DURATION', 'INSTALL_RATE', 'AGE', 'NUM_CREDITS', 'AMOUNT']\n",
    "preprocessed_df = dummied_df.copy()\n",
    "preprocessed_df[scaling_cols] = (preprocessed_df[scaling_cols]-preprocessed_df[scaling_cols].min()) / (preprocessed_df[scaling_cols].max()-preprocessed_df[scaling_cols].min())\n",
    "\n",
    "# change Label\n",
    "preprocessed_df.RESPONSE = df.RESPONSE-1\n",
    "\n",
    "# split X, y \n",
    "X, y = preprocessed_df.drop('RESPONSE', axis=1), preprocessed_df.RESPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-Test Split : `sklearn.model_selection.train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split with 'stratify'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `sklearn.linear_model.LogisiticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# parameters\n",
    "\n",
    "# model\n",
    "\n",
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def result(fitted_model, X_test, y_test):\n",
    "    # pred \n",
    "    # score\n",
    "    # conf_mat\n",
    "    return [pred, score, conf_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# result\n",
    "raw_result = result(raw_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. RFE : Recursive Feature Elimination `sklearn.feature_selection.RFE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimator & selector\n",
    "selector = RFE(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit to selector\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_features_, ranking, support\n",
    "print(selector.n_features_)\n",
    "print(selector.ranking_)\n",
    "print(selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change X to selected_X_train, selected_X_test\n",
    "# selected_cols = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fitting new model\n",
    "# RFE_model = \n",
    "\n",
    "# get result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1-3. PCA : `sklearn.decompostion.pca`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameter : n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pca_model = \n",
    "\n",
    "for n in n_components:\n",
    "    # decomposer\n",
    "    # fit\n",
    "    # .transform\n",
    "    print(n, sum(pca_decomposer.explained_variance_ratio_))\n",
    "    \n",
    "    # fit new estimator\n",
    "    # result()\n",
    "    print(pca_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4. 실습 : 변수 선택을 활용한 신용 등급 분류 모델 만들기\n",
    "---\n",
    "1. 변수 선택을 적용한 신용 등급 분류 모델 만들기\n",
    "    * RFE, PCA 중 반드시 하나를 사용할 것\n",
    "    * 변수 선택 하지 않은 모델(모든 변수를 사용한 모델)과 성능을 비교할 것\n",
    "    \n",
    "2. 변수 선택을 활용했을 때의 장점은 무엇인가?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text Mining\n",
    "---\n",
    "#### 2-1. Data : The Internet Movie Script Database (IMSDb)\n",
    ".txt 파일을 받을 수 있는 사이트 - https://figshare.com/projects/imsdb_movie_scripts/18907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv('imsdb_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Task] 3개의 영화 script를 다운로드 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. Preprocessing : tokenizing, stemming, removing stopwords\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# tokenizer\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# .stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# .words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessed(raw_script):\n",
    "    # tokenize\n",
    "    \n",
    "    # stemming\n",
    "\n",
    "    # removing stopwords\n",
    "    return ' '.join(stopwords_removed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 실습 : 나머지 2개의 영화에 대해서도 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed_scripts = [preprocessed_1, preprocessed_2, preporcessed_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#### 2-3. Word Cloud\n",
    "---\n",
    "`conda install -c https://conda.anaconda.org/amueller wordcloud`\n",
    "- [Reference](https://github.com/amueller/word_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag of words : `sklearn.feature_extraction.text.CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Cloud : `wordcloud.WordCloud`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort bows by count\n",
    "# vocabs\n",
    "# counts\n",
    "# sorted_bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wordcloud.fit_words(list of tuples (word, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# is there more words to remove?\n",
    "sorted_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words\n",
    "# stopwords_for_scripts\n",
    "# filtered_sorted_bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2-4. TF-IDF : `sklearn.feature_extraction.text.TfidfTransformer`\n",
    "---\n",
    "- TF(Term Frequency) : 해당 단어가 얼마나 '자주' 등장하는지 알 수 있음\n",
    "- IDF(Inverse Document Frequency) : 해당 단어가 얼마나 '희귀하게' 등장하는지 알 수 있음\n",
    "- ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted_tfidf\n",
    "\n",
    "# remove words\n",
    "\n",
    "# wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 실습 : 나머지 2개의 영화에 대한 word cloud 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
